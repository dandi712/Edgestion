{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "import requests\r\n",
    "import pandas as pd\r\n",
    "from bs4 import BeautifulSoup\r\n",
    "import re\r\n",
    "import json\r\n",
    "import time\r\n",
    "import glob\r\n",
    "from selenium import webdriver\r\n",
    "import time\r\n",
    "import pymssql #运行此程序前，需要安装pymssql\r\n",
    "import pandas as pd\r\n",
    "import key\r\n",
    "\r\n",
    "from sqlalchemy import create_engine\r\n",
    "from sqlalchemy.types import NVARCHAR, INT,Text"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "def ACS_updatedownload(key):\r\n",
    "    conn = pymssql.connect(host=key.sql.host, port=key.sql.port ,user=key.sql.username, password=key.sql.password)\r\n",
    "    query = \"select doi from [BP_Extension].[dbo].[ACS_Edsug]\"\r\n",
    "    df_utnull = pd.read_sql(query,con=conn)\r\n",
    "    lst_doi = list(df_utnull['doi'])\r\n",
    "    # 提交之前的操作，如果之前已经执行多次的execute，那么就都进行提交\r\n",
    "    # 关闭connection对象\r\n",
    "    conn.close()\r\n",
    "    # 创建connection连接\r\n",
    "    tag = 1\r\n",
    "    #lst_dic = []\r\n",
    "\r\n",
    "    tag = 1\r\n",
    "    #lst_doi = []\r\n",
    "    lst_dic = []\r\n",
    "    while(tag):\r\n",
    "        print(tag)\r\n",
    "        u = \"https://pubs.acs.org/editorschoice/?widgetSort=EditorsChoiceDate&widgetFilter=&widgetPage=\" + str(tag-1)\r\n",
    "        r = requests.get(u)\r\n",
    "        soupi = BeautifulSoup(r.text, 'lxml')\r\n",
    "\r\n",
    "        for i in range(len(soupi.find_all('div',class_ = 'issue-item clearfix'))):\r\n",
    "            #print(i)\r\n",
    "\r\n",
    "            dic = {}\r\n",
    "            contenti = str(soupi.find_all('div',class_ = 'issue-item clearfix')[i])\r\n",
    "            try:\r\n",
    "                dic['img_paper'] = re.match('[\\s\\S]*\"Article figure\" class=\"lazy\" data-src=\"([\\s\\S]*?)\"/><noscript>[\\s\\S]*',contenti).group(1)\r\n",
    "            except:\r\n",
    "                1\r\n",
    "            try:\r\n",
    "                dic['img_journal'] = re.match('[\\s\\S]*alt=\"Journal logo\" src=\"([\\s\\S]*)\"/></noscript>[\\s\\S]*',contenti).group(1)\r\n",
    "            except:\r\n",
    "                1\r\n",
    "            dic['doi'] = re.match('[\\s\\S]*\"issue-item_title\"><a href=\"/([\\s\\S]*?)\" title=\"[\\s\\S]*',contenti).group(1).replace('doi/','')\r\n",
    "            dic['title'] = soupi.find_all('h5',class_ ='issue-item_title')[i].text\r\n",
    "            dic['authors'] = soupi.find_all('ul',class_ ='rlist--inline loa mobile-authors issue-item_loa')[i].text.replace('\\xa0',' ')\r\n",
    "            dic['journal_full'] = soupi.find_all('div',class_ ='issue-item_info_list')[i].text\r\n",
    "            dic['journal'] = re.match('[\\s\\S]*issue-item_jour-name\"><i>([\\s\\S]*)</i></span>[\\s\\S]*',contenti,re.M).group(1)\r\n",
    "\r\n",
    "            dic['year'] = re.match('[\\s\\S]*<span class=\"issue-item_yearpubdate\"> <span>([\\s\\S]*?)</span></span>[\\s\\S]*',contenti).group(1)\r\n",
    "            dic['paper_type'] = re.match('[\\s\\S]*<span class=\"issue-item_type\"> \\(([\\s\\S]*?)\\)</span>[\\s\\S]*',contenti).group(1)\r\n",
    "            dic['pubulicationdata'] = soupi.find_all('span',class_='issue-item_pubdate')[i+i].text\r\n",
    "            try:\r\n",
    "                dic['choicedate'] = re.match('[\\s\\S]*ACS Editors\\' Choice Date</span><span class=\"date-separator\">:</span>([\\s\\S]*?)</span>[\\s\\S]*',contenti).group(1)\r\n",
    "            except:\r\n",
    "                1\r\n",
    "            key = soupi.find_all('ul',class_='issue-item_buttons-list')[i].find_all('li')[0].a['title']\r\n",
    "            dic[key] = soupi.find_all('ul',class_='issue-item_buttons-list')[i].find_all('li')[0].a['href']\r\n",
    "            try:\r\n",
    "                dic['fulltext_link'] = re.match('[\\s\\S]*<li><a href=\"([\\s\\S]*?)\" title=\"Full text\">[\\s\\S]*',contenti).group(1)\r\n",
    "            except:\r\n",
    "                1\r\n",
    "            dic['pdf_link'] = re.match('[\\s\\S]*<li><a href=\"([\\s\\S]*?)\" title=\"PDF\"[\\s\\S]*',contenti).group(1)\r\n",
    "            try:\r\n",
    "                dic['abstract'] = soupi.find_all('div',class_='issue-item_footer')[i].find('div').find('div').text\r\n",
    "            except:\r\n",
    "                1\r\n",
    "            #print(dic['title'])\r\n",
    "            if dic['doi'] not in lst_doi:\r\n",
    "                lst_doi.append(dic['doi'])\r\n",
    "                lst_dic.append(dic)\r\n",
    "            else:\r\n",
    "                tag = -1\r\n",
    "                break\r\n",
    "        tag = tag + 1\r\n",
    "        print('记录数',len(lst_dic))\r\n",
    "    print('爬取完毕')\r\n",
    "    print(len(lst_dic))\r\n",
    "    return(lst_dic)\r\n",
    "def ACSprocess(lst_dic):\r\n",
    "    '''\r\n",
    "    输入数据字典列表\r\n",
    "    '''\r\n",
    "    if len(lst_dic) >0:\r\n",
    "        print('开始数据处理')\r\n",
    "        df = pd.DataFrame(lst_dic)\r\n",
    "        df['img_paper_fix'] = 'https://pubs.acs.org' + df['img_paper']\r\n",
    "        df['img_journal_fix'] = 'https://pubs.acs.org' + df['img_journal']\r\n",
    "        df['doi'] = df['doi'].str.replace('doi/','')\r\n",
    "\r\n",
    "        df['Abstract_fix'] = 'https://pubs.acs.org' + df['Abstract']\r\n",
    "        df['Abstract_link'] = df['Abstract']\r\n",
    "        df = df.drop('Abstract',axis =1)\r\n",
    "        df['fulltext_link_fix'] = 'https://pubs.acs.org' + df['fulltext_link']\r\n",
    "        df['pdf_link_fix'] = 'https://pubs.acs.org' + df['pdf_link']\r\n",
    "        try:\r\n",
    "            df['First_page_fix'] = 'https://pubs.acs.org' + df['First Page']\r\n",
    "        except:\r\n",
    "            1\r\n",
    "        try:\r\n",
    "            df['Fulltext_fix'] = 'https://pubs.acs.org' + df['Full text']\r\n",
    "        except:\r\n",
    "            1\r\n",
    "        print('数据处理完成')\r\n",
    "        return df\r\n",
    "    else:\r\n",
    "        print('无处理记录')\r\n",
    "        return pd.DataFrame()\r\n",
    "\r\n",
    "def CASuploadData(df,key):\r\n",
    "    conn = create_engine('mssql+pymssql://'+ key.sql.username +':' + key.sql.password+ '@' + key.sql.host+ '/BP_Extension')\r\n",
    "    dtypedict = {\r\n",
    "        'img_paper' : NVARCHAR(length=255),\r\n",
    "        'img_journal' : NVARCHAR(length=255),\r\n",
    "        'doi': NVARCHAR(length=255),\r\n",
    "        'title': Text(),\r\n",
    "        'authors': Text(),\r\n",
    "        'journal_full': NVARCHAR(length=255),\r\n",
    "        'Abstract': NVARCHAR(length=255),\r\n",
    "        'fulltext_link': NVARCHAR(length=255),\r\n",
    "        'pdf_link': NVARCHAR(length=255),\r\n",
    "        'PDF': NVARCHAR(length=255),\r\n",
    "        '[First Page]': NVARCHAR(length=255),\r\n",
    "        '[Full text]': NVARCHAR(length=255),\r\n",
    "        'img_paper_fix': NVARCHAR(length=255),\r\n",
    "        'img_journal_fix': NVARCHAR(length=255),\r\n",
    "        'Abstract_fix': NVARCHAR(length=255),\r\n",
    "        'fulltext_link_fix': NVARCHAR(length=255),\r\n",
    "        'pdf_link_fix': NVARCHAR(length=255),\r\n",
    "        'First_page_fix': NVARCHAR(length=255),\r\n",
    "        'Fulltext_fix': NVARCHAR(length=255),\r\n",
    "        'ACS_tag': INT(),\r\n",
    "        'UT': NVARCHAR(length=255)\r\n",
    "    }\r\n",
    "    df.to_sql(name='ACS_Edsug', con=conn, if_exists='replace', index=False, dtype=dtypedict)\r\n",
    "    conn.dispose()\r\n",
    "\r\n",
    "def QueryGener_ACS(key):\r\n",
    "    conn = pymssql.connect(host=key.sql.host, port=key.sql.port ,user=key.sql.username, password=key.sql.password)\r\n",
    "    query = \"select doi,title,UT from [BP_Extension].[dbo].[ACS_Edsug] where UT = '' or UT = 'nan'\"\r\n",
    "    df = pd.read_sql(query,con=conn)\r\n",
    "    conn.close()\r\n",
    "    query = ''\r\n",
    "    for i in range(len(df)):\r\n",
    "        queryi = 'DO = (' + df.iloc[i]['doi'] + ')'\r\n",
    "        if i == 0:\r\n",
    "            query = queryi\r\n",
    "            continue\r\n",
    "        query = query + ' OR ' + queryi\r\n",
    "\r\n",
    "    newfile = './Query_ACS.txt'\r\n",
    "    with open(newfile,'w') as f:\r\n",
    "        f.write(query)\r\n",
    "    print('检索式生成完成')\r\n",
    "def Updatewos_ACS(df_all):\r\n",
    "    try:\r\n",
    "        df_all['doi'] = df_all['DOI'].astype('str')\r\n",
    "        df_all['UT'] = df_all['UT (Unique ID)'].astype('str')\r\n",
    "    except:\r\n",
    "        df_all['doi'] = df_all['doi'].astype('str')\r\n",
    "        df_all['UT'] = df_all['UT'].astype('str')\r\n",
    "    conn = pymssql.connect(host=key.sql.host, port=key.sql.port ,user=key.sql.username, password=key.sql.password)\r\n",
    "    # 获取cursor对象\r\n",
    "    cs1 = conn.cursor()\r\n",
    "    for i in range(len(df_all)):\r\n",
    "        query = \"update [BP_Extension].[dbo].[ACS_Edsug] set UT = '\" + df_all.iloc[i]['UT'] +\"' where doi = '\" + df_all.iloc[i]['doi'] +\"'\"\r\n",
    "        cs1.execute(query)\r\n",
    "    # 提交之前的操作，如果之前已经执行多次的execute，那么就都进行提交\r\n",
    "    conn.commit()\r\n",
    "    # 关闭cursor对象\r\n",
    "    cs1.close()\r\n",
    "    # 关闭connection对象\r\n",
    "    conn.close()\r\n",
    "    # 创建connection连接\r\n",
    "    print('完成更新，共',len(df_all),'条记录')\r\n",
    "def Check_ACS():\r\n",
    "    conn = pymssql.connect(host=key.sql.host, port=key.sql.port ,user=key.sql.username, password=key.sql.password)\r\n",
    "    query = \"select doi,title,UT from [BP_Extension].[dbo].[ACS_Edsug] where UT = '' or UT = 'nan'\"\r\n",
    "    df_utnull = pd.read_sql(query,con=conn)\r\n",
    "    # 提交之前的操作，如果之前已经执行多次的execute，那么就都进行提交\r\n",
    "    # 关闭connection对象\r\n",
    "    conn.close()\r\n",
    "    # 创建connection连接\r\n",
    "    df_utnull = df_utnull[['doi','UT','title']]\r\n",
    "    print('仍有',len(df_utnull),'条空记录请检查acs_null.csv文件')\r\n",
    "    df_utnull.to_csv(r'./acs_null.csv',index = False)\r\n",
    "\r\n",
    "def Concat_xls(files):\r\n",
    "    files = r\"./\" + files + \"/*.xls\"\r\n",
    "    df_all = pd.DataFrame()\r\n",
    "    lst = glob.glob(files)\r\n",
    "    for li in lst:\r\n",
    "        dfi = pd.read_excel(li)\r\n",
    "        df_all = pd.concat([df_all,dfi])\r\n",
    "    return df_all"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "def Openwos():\r\n",
    "    brower = webdriver.Chrome()\r\n",
    "    #检索结果页地址\r\n",
    "    url = \"https://www.webofscience.com/wos/alldb/basic-search\"\r\n",
    "    brower.get(url)\r\n",
    "    return brower\r\n",
    "\r\n",
    "def Crul(brower):\r\n",
    "    time.sleep(3)\r\n",
    "    #设置爬取页面\r\n",
    "    #handles = brower.window_handles\r\n",
    "    #brower.switch_to_window(handles[3])\r\n",
    "    num = brower.find_element_by_xpath('/html/body/app-wos/div/div/main/div/app-input-route/app-base-summary-component/app-search-friendly-display/div[1]/app-general-search-friendly-display/h1/span').text.replace(',','')\r\n",
    "    page1000 = int(int(num)/1000)+1\r\n",
    "    count = 0\r\n",
    "    try:\r\n",
    "        brower.find_element_by_xpath('//*[@id=\"pendo-close-guide-8fdced48\"]').click()\r\n",
    "        time.sleep(2)\r\n",
    "        brower.find_element_by_xpath('//*[@id=\"pendo-close-guide-dc656865\"]').click()\r\n",
    "        time.sleep(1)\r\n",
    "    except:\r\n",
    "        1\r\n",
    "    for i in range(page1000):\r\n",
    "    #也可设置为从第n开始\r\n",
    "    #for i in range(n, 120):\r\n",
    "        count += 1\r\n",
    "        if count ==60:\r\n",
    "            time.sleep(30)\r\n",
    "        #如果爬取超过90页，就休眠120S，可以自行设置页数\r\n",
    "        print(\"第\" + str(i+1) + \"次\")     \r\n",
    "        \r\n",
    "        time.sleep(7)\r\n",
    "        brower.find_element_by_xpath('//*[@id=\"snRecListTop\"]/app-export-menu/div/button').click()\r\n",
    "        time.sleep(1)\r\n",
    "        brower.find_element_by_xpath('//*[@id=\"exportToExcelButton\"]').click()\r\n",
    "        \r\n",
    "        #点击recordfrom\r\n",
    "\r\n",
    "        time.sleep(1)\r\n",
    "        brower.find_element_by_xpath('//*[@id=\"radio3\"]/label/span[2]').click() \r\n",
    "        time.sleep(1)\r\n",
    "\r\n",
    "        start = brower.find_element_by_xpath('/html/body/app-wos/div/div/main/app-input-route/app-export-overlay/div/div[3]/div[2]/app-export-out-details/div/div[2]/div/fieldset/mat-radio-group/div[3]/mat-form-field[1]/div/div[1]/div/input')\r\n",
    "        end = brower.find_element_by_xpath('/html/body/app-wos/div/div/main/app-input-route/app-export-overlay/div/div[3]/div[2]/app-export-out-details/div/div[2]/div/fieldset/mat-radio-group/div[3]/mat-form-field[2]/div/div[1]/div/input')\r\n",
    "        start.clear()\r\n",
    "        end.clear()\r\n",
    "        if i != page1000-1:\r\n",
    "            start_no = 1 + i*1000\r\n",
    "            end_no =  1000 + i*1000\r\n",
    "        else:\r\n",
    "            start_no = end_no + 1\r\n",
    "            end_no = num\r\n",
    "        start.send_keys(start_no)\r\n",
    "        end.send_keys(end_no)\r\n",
    "        time.sleep(1)\r\n",
    "\r\n",
    "        #选择record content\r\n",
    "        brower.find_element_by_xpath('/html/body/app-wos/div/div/main/app-input-route/app-export-overlay/div/div[3]/div[2]/app-export-out-details/div/div[2]/div/div[1]/wos-select/button').click()\r\n",
    "        brower.find_element_by_xpath('//*[@id=\"global-select\"]/div/div[2]/div[1]').click()\r\n",
    "\r\n",
    "        brower.find_element_by_xpath('/html/body/app-wos/div/div/main/app-input-route/app-export-overlay/div/div[3]/div[2]/app-export-out-details/div/div[2]/div/div[2]/button[1]/span[1]/span').click()\r\n",
    "        time.sleep(7)\r\n",
    "    print('下载完成')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def ACS():\r\n",
    "    starttime = time.time()\r\n",
    "    lst_dic = ACSdownload()\r\n",
    "    df = ACSprocess(lst_dic)\r\n",
    "    QueryGener(file)\r\n",
    "    print('finish')\r\n",
    "    endtime = time.time()\r\n",
    "    print('总耗时', endtime - starttime, 'S')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "lst_dic = ACS_updatedownload(key)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "记录数 20\n",
      "2\n",
      "记录数 40\n",
      "3\n",
      "记录数 60\n",
      "4\n",
      "记录数 80\n",
      "5\n",
      "记录数 100\n",
      "6\n",
      "记录数 120\n",
      "7\n",
      "记录数 140\n",
      "8\n",
      "记录数 160\n",
      "9\n",
      "记录数 180\n",
      "10\n",
      "记录数 200\n",
      "11\n",
      "记录数 220\n",
      "12\n",
      "记录数 240\n",
      "13\n",
      "记录数 260\n",
      "14\n",
      "记录数 280\n",
      "15\n",
      "记录数 300\n",
      "16\n",
      "记录数 320\n",
      "17\n",
      "记录数 340\n",
      "18\n",
      "记录数 360\n",
      "19\n",
      "记录数 380\n",
      "20\n",
      "记录数 400\n",
      "21\n",
      "记录数 420\n",
      "22\n",
      "记录数 440\n",
      "23\n",
      "记录数 460\n",
      "24\n",
      "记录数 480\n",
      "25\n",
      "记录数 500\n",
      "26\n",
      "记录数 520\n",
      "27\n",
      "记录数 540\n",
      "28\n",
      "记录数 560\n",
      "29\n",
      "记录数 580\n",
      "30\n",
      "记录数 600\n",
      "31\n",
      "记录数 620\n",
      "32\n",
      "记录数 640\n",
      "33\n",
      "记录数 660\n",
      "34\n",
      "记录数 680\n",
      "35\n",
      "记录数 700\n",
      "36\n",
      "记录数 720\n",
      "37\n",
      "记录数 740\n",
      "38\n",
      "记录数 760\n",
      "39\n",
      "记录数 780\n",
      "40\n",
      "记录数 800\n",
      "41\n",
      "记录数 820\n",
      "42\n",
      "记录数 840\n",
      "43\n",
      "记录数 860\n",
      "44\n",
      "记录数 880\n",
      "45\n",
      "记录数 900\n",
      "46\n",
      "记录数 920\n",
      "47\n",
      "记录数 940\n",
      "48\n",
      "记录数 960\n",
      "49\n",
      "记录数 980\n",
      "50\n",
      "记录数 1000\n",
      "51\n",
      "记录数 1020\n",
      "52\n",
      "记录数 1040\n",
      "53\n",
      "记录数 1060\n",
      "54\n",
      "记录数 1080\n",
      "55\n",
      "记录数 1100\n",
      "56\n",
      "记录数 1120\n",
      "57\n",
      "记录数 1140\n",
      "58\n",
      "记录数 1160\n",
      "59\n",
      "记录数 1180\n",
      "60\n",
      "记录数 1200\n",
      "61\n",
      "记录数 1220\n",
      "62\n",
      "记录数 1240\n",
      "63\n",
      "记录数 1260\n",
      "64\n",
      "记录数 1280\n",
      "65\n",
      "记录数 1300\n",
      "66\n",
      "记录数 1320\n",
      "67\n",
      "记录数 1340\n",
      "68\n",
      "记录数 1360\n",
      "69\n",
      "记录数 1380\n",
      "70\n",
      "记录数 1400\n",
      "71\n",
      "记录数 1420\n",
      "72\n",
      "记录数 1440\n",
      "73\n",
      "记录数 1460\n",
      "74\n",
      "记录数 1480\n",
      "75\n",
      "记录数 1500\n",
      "76\n",
      "记录数 1520\n",
      "77\n",
      "记录数 1540\n",
      "78\n",
      "记录数 1560\n",
      "79\n",
      "记录数 1580\n",
      "80\n",
      "记录数 1600\n",
      "81\n",
      "记录数 1620\n",
      "82\n",
      "记录数 1640\n",
      "83\n",
      "记录数 1660\n",
      "84\n",
      "记录数 1680\n",
      "85\n",
      "记录数 1700\n",
      "86\n",
      "记录数 1720\n",
      "87\n",
      "记录数 1740\n",
      "88\n",
      "记录数 1760\n",
      "89\n",
      "记录数 1780\n",
      "90\n",
      "记录数 1800\n",
      "91\n",
      "记录数 1820\n",
      "92\n",
      "记录数 1840\n",
      "93\n",
      "记录数 1860\n",
      "94\n",
      "记录数 1880\n",
      "95\n",
      "记录数 1900\n",
      "96\n",
      "记录数 1920\n",
      "97\n",
      "记录数 1940\n",
      "98\n",
      "记录数 1960\n",
      "99\n",
      "记录数 1980\n",
      "100\n",
      "记录数 2000\n",
      "101\n",
      "记录数 2020\n",
      "102\n",
      "记录数 2020\n",
      "爬取完毕\n",
      "2020\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "df = ACSprocess(lst_dic)\r\n",
    "df['ACS_tag'] = 1\r\n",
    "df['UT'] = ''"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "开始数据处理\n",
      "数据处理完成\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "CASuploadData(df,key)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "QueryGener_ACS(key)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "检索式生成完成\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "Check()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "仍有 2020 条空记录请检查acs_null.csv文件\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "borwer = Openwos()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "Crul(borwer)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "第1次\n",
      "第2次\n",
      "第3次\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "df_all = Concat_xls('ACS')\r\n",
    "df_all[df_all.duplicated('DOI',keep = False)][['DOI','UT (Unique ID)','Article Title']]\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                             DOI       UT (Unique ID)  \\\n",
       "34      10.1021/acs.jpca.1c05194  WOS:000672731100001   \n",
       "35      10.1021/acs.jpca.1c05194     MEDLINE:34259000   \n",
       "36      10.1021/acs.jpca.1c05194     MEDLINE:34181417   \n",
       "173      10.1021/acsnano.8b00047  WOS:000436216800002   \n",
       "226      10.1021/acsnano.8b00047  WOS:000431088200011   \n",
       "425  10.1021/acsinfecdis.7b00064  WOS:000417405100003   \n",
       "457  10.1021/acsinfecdis.7b00064  WOS:000407771400006   \n",
       "\n",
       "                                         Article Title  \n",
       "34   A Black Scientist's Retrospective of His Life ...  \n",
       "35   A Black Scientist's Retrospective of His Life ...  \n",
       "36   A Black Scientist's Retrospective of His Life ...  \n",
       "173     Fire-resistant nano-wallpaper sounds the alarm  \n",
       "226  Fire Alarm Wallpaper Based on Fire-Resistant H...  \n",
       "425                Sugar in Breast Milk kills Bacteria  \n",
       "457  Human Milk Oligosaccharides Exhibit Antimicrob...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOI</th>\n",
       "      <th>UT (Unique ID)</th>\n",
       "      <th>Article Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>10.1021/acs.jpca.1c05194</td>\n",
       "      <td>WOS:000672731100001</td>\n",
       "      <td>A Black Scientist's Retrospective of His Life ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>10.1021/acs.jpca.1c05194</td>\n",
       "      <td>MEDLINE:34259000</td>\n",
       "      <td>A Black Scientist's Retrospective of His Life ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>10.1021/acs.jpca.1c05194</td>\n",
       "      <td>MEDLINE:34181417</td>\n",
       "      <td>A Black Scientist's Retrospective of His Life ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>10.1021/acsnano.8b00047</td>\n",
       "      <td>WOS:000436216800002</td>\n",
       "      <td>Fire-resistant nano-wallpaper sounds the alarm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>10.1021/acsnano.8b00047</td>\n",
       "      <td>WOS:000431088200011</td>\n",
       "      <td>Fire Alarm Wallpaper Based on Fire-Resistant H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>10.1021/acsinfecdis.7b00064</td>\n",
       "      <td>WOS:000417405100003</td>\n",
       "      <td>Sugar in Breast Milk kills Bacteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>10.1021/acsinfecdis.7b00064</td>\n",
       "      <td>WOS:000407771400006</td>\n",
       "      <td>Human Milk Oligosaccharides Exhibit Antimicrob...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "df_all = df_all[df_all['UT (Unique ID)'] != 'WOS:000436216800002']\r\n",
    "df_all = df_all[df_all['UT (Unique ID)'] != 'WOS:000417405100003']\r\n",
    "df_all = df_all[df_all['UT (Unique ID)'] != 'MEDLINE:34259000']\r\n",
    "df_all = df_all[df_all['UT (Unique ID)'] != 'MEDLINE:34181417']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "Updatewos(df_all)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "完成更新，共 1998 条记录\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "Check()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "仍有 27 条空记录请检查acs_null.csv文件\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "#增加UT后进行\r\n",
    "df = pd.read_csv(r'./acs_null.csv')\r\n",
    "Updatewos(df)\r\n",
    "Check()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "完成更新，共 27 条记录\n",
      "仍有 23 条空记录请检查acs_null.csv文件\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 进行数据更新"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "lst_dic = ACS_updatedownload(key)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "记录数 0\n",
      "爬取完毕\n",
      "0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "df = ACSprocess(lst_dic)\r\n",
    "if len(df) >0:\r\n",
    "    df['ACS_tag'] = 1\r\n",
    "    df['UT'] = ''\r\n",
    "    uploadData(df,key)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "无处理记录\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "QueryGener_ACS(key)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "检索式生成完成\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = pd.read_csv(r'./acs_null.csv')\r\n",
    "Updatewos(df)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "07efdcd4b820c98a756949507a4d29d7862823915ec7477944641bea022f4f62"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}